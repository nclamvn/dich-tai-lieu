#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Deepseek OCR Integration - Nh·∫≠n d·∫°ng vƒÉn b·∫£n vi·∫øt tay & scan
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

T√≠nh nƒÉng:
- Nh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay (handwriting recognition)
- OCR cho t√†i li·ªáu scan (scanned documents)
- H·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ (Vi·ªát, Anh, Trung, Nh·∫≠t, H√†n)
- T·ª± ƒë·ªông ph√°t hi·ªán v√πng vƒÉn b·∫£n
- X·ª≠ l√Ω ·∫£nh ch·∫•t l∆∞·ª£ng th·∫•p
- Integration v·ªõi translation pipeline

API: https://platform.deepseek.com
"""

import base64
import httpx
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
import asyncio


@dataclass
class OCRResult:
    """K·∫øt qu·∫£ OCR"""
    text: str
    confidence: float
    language: str
    regions: List[Dict[str, Any]]
    processing_time: float


class DeepseekOCR:
    """
    Deepseek OCR Client cho nh·∫≠n d·∫°ng vƒÉn b·∫£n t·ª´ ·∫£nh

    Features:
    - Handwriting recognition (ch·ªØ vi·∫øt tay)
    - Document OCR (t√†i li·ªáu scan)
    - Multi-language support
    - Image preprocessing
    - Text region detection
    """

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://api.deepseek.com/v1",
        timeout: int = 60
    ):
        """
        Kh·ªüi t·∫°o Deepseek OCR client

        Args:
            api_key: Deepseek API key
            base_url: API base URL
            timeout: Request timeout (seconds)
        """
        self.api_key = api_key
        self.base_url = base_url
        self.timeout = timeout

        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    async def recognize_image(
        self,
        image_path: str,
        language: str = "auto",
        mode: str = "accurate"
    ) -> OCRResult:
        """
        Nh·∫≠n d·∫°ng vƒÉn b·∫£n t·ª´ ·∫£nh

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n file ·∫£nh
            language: Ng√¥n ng·ªØ (auto, vi, en, zh, ja, ko)
            mode: Ch·∫ø ƒë·ªô nh·∫≠n d·∫°ng (fast/accurate/handwriting)

        Returns:
            OCRResult v·ªõi vƒÉn b·∫£n ƒë√£ nh·∫≠n d·∫°ng

        Example:
            >>> ocr = DeepseekOCR(api_key="sk-xxx")
            >>> result = await ocr.recognize_image("scan.jpg")
            >>> print(result.text)
            "ƒê√¢y l√† vƒÉn b·∫£n ƒë∆∞·ª£c nh·∫≠n d·∫°ng..."
        """
        import time
        start_time = time.time()

        # ƒê·ªçc v√† encode ·∫£nh
        image_data = self._encode_image(image_path)

        # G·ªçi API
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.base_url}/ocr/recognize",
                headers=self.headers,
                json={
                    "image": image_data,
                    "language": language,
                    "mode": mode,
                    "features": {
                        "detect_regions": True,
                        "confidence_threshold": 0.7,
                        "auto_rotate": True,
                        "enhance_quality": True
                    }
                }
            )
            response.raise_for_status()
            data = response.json()

        processing_time = time.time() - start_time

        return OCRResult(
            text=data.get("text", ""),
            confidence=data.get("confidence", 0.0),
            language=data.get("detected_language", language),
            regions=data.get("regions", []),
            processing_time=processing_time
        )

    async def recognize_handwriting(
        self,
        image_path: str,
        language: str = "vi"
    ) -> OCRResult:
        """
        Nh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay (handwriting recognition)

        T·ªëi ∆∞u h√≥a cho:
        - Ch·ªØ vi·∫øt tay ti·∫øng Vi·ªát
        - Ghi ch√∫ h·ªçc t·∫≠p
        - Bi√™n b·∫£n h·ªçp
        - ƒê∆°n t·ª´

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n file ·∫£nh ch·ªØ vi·∫øt tay
            language: Ng√¥n ng·ªØ (vi, en, zh)

        Returns:
            OCRResult v·ªõi vƒÉn b·∫£n vi·∫øt tay ƒë√£ nh·∫≠n d·∫°ng
        """
        return await self.recognize_image(
            image_path,
            language=language,
            mode="handwriting"
        )

    async def recognize_batch(
        self,
        image_paths: List[str],
        language: str = "auto",
        max_concurrent: int = 3
    ) -> List[OCRResult]:
        """
        Nh·∫≠n d·∫°ng h√†ng lo·∫°t ·∫£nh

        Args:
            image_paths: Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh
            language: Ng√¥n ng·ªØ
            max_concurrent: S·ªë request ƒë·ªìng th·ªùi t·ªëi ƒëa

        Returns:
            List OCRResult cho t·ª´ng ·∫£nh
        """
        semaphore = asyncio.Semaphore(max_concurrent)

        async def process_one(path: str) -> OCRResult:
            async with semaphore:
                return await self.recognize_image(path, language)

        tasks = [process_one(path) for path in image_paths]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Filter out exceptions
        return [r for r in results if isinstance(r, OCRResult)]

    async def recognize_with_translation(
        self,
        image_path: str,
        target_lang: str = "vi",
        translator_api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Nh·∫≠n d·∫°ng ·∫£nh v√† d·ªãch lu√¥n

        Workflow:
        1. OCR: Nh·∫≠n d·∫°ng vƒÉn b·∫£n t·ª´ ·∫£nh
        2. Detect: Ph√°t hi·ªán ng√¥n ng·ªØ ngu·ªìn
        3. Translate: D·ªãch sang ng√¥n ng·ªØ ƒë√≠ch

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
            target_lang: Ng√¥n ng·ªØ ƒë√≠ch
            translator_api_key: API key cho translation (optional)

        Returns:
            Dict ch·ª©a c·∫£ OCR result v√† translation
        """
        # B∆∞·ªõc 1: OCR
        ocr_result = await self.recognize_image(image_path)

        # B∆∞·ªõc 2: Translation (n·∫øu c·∫ßn)
        translated_text = ocr_result.text
        if translator_api_key and ocr_result.language != target_lang:
            # TODO: Integrate v·ªõi TranslatorEngine
            # T·∫°m th·ªùi return original text
            pass

        return {
            "ocr": {
                "text": ocr_result.text,
                "confidence": ocr_result.confidence,
                "language": ocr_result.language,
                "processing_time": ocr_result.processing_time
            },
            "translation": {
                "text": translated_text,
                "source_lang": ocr_result.language,
                "target_lang": target_lang
            },
            "regions": ocr_result.regions
        }

    def _encode_image(self, image_path: str) -> str:
        """
        Encode ·∫£nh sang base64

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n file ·∫£nh

        Returns:
            Base64 encoded string
        """
        path = Path(image_path)
        if not path.exists():
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")

        with open(path, "rb") as f:
            image_bytes = f.read()

        return base64.b64encode(image_bytes).decode("utf-8")

    @staticmethod
    def preprocess_image(
        image_path: str,
        output_path: Optional[str] = None,
        enhance: bool = True,
        deskew: bool = True
    ) -> str:
        """
        Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c OCR

        Operations:
        - TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
        - Kh·ª≠ nhi·ªÖu
        - Ch·ªânh g√≥c nghi√™ng
        - Binarization (ƒëen tr·∫Øng)

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh g·ªëc
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω
            enhance: TƒÉng ch·∫•t l∆∞·ª£ng
            deskew: Ch·ªânh g√≥c nghi√™ng

        Returns:
            ƒê∆∞·ªùng d·∫´n ·∫£nh ƒë√£ x·ª≠ l√Ω

        Note:
            Requires: pillow, opencv-python
        """
        try:
            from PIL import Image, ImageEnhance, ImageFilter
            import numpy as np
        except ImportError:
            print("‚ö†Ô∏è  C·∫ßn c√†i ƒë·∫∑t: pip install pillow opencv-python")
            return image_path

        img = Image.open(image_path)

        # Convert to grayscale
        img = img.convert('L')

        if enhance:
            # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(2.0)

            # TƒÉng ƒë·ªô s·∫Øc n√©t
            img = img.filter(ImageFilter.SHARPEN)

        if deskew:
            # TODO: Implement deskewing v·ªõi OpenCV
            pass

        # L∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω
        if not output_path:
            output_path = str(Path(image_path).with_suffix('.processed.png'))

        img.save(output_path)
        return output_path


# =============================================================================
# Helper Functions
# =============================================================================

async def ocr_and_translate(
    image_path: str,
    deepseek_api_key: str,
    openai_api_key: str,
    source_lang: str = "auto",
    target_lang: str = "vi"
) -> Dict[str, Any]:
    """
    Helper function: OCR + Translation trong m·ªôt l·∫ßn g·ªçi

    Args:
        image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
        deepseek_api_key: Deepseek API key
        openai_api_key: OpenAI API key
        source_lang: Ng√¥n ng·ªØ ngu·ªìn (auto detect)
        target_lang: Ng√¥n ng·ªØ ƒë√≠ch

    Returns:
        Dict v·ªõi OCR result v√† translation

    Example:
        >>> result = await ocr_and_translate(
        ...     "handwriting.jpg",
        ...     deepseek_key="sk-xxx",
        ...     openai_key="sk-yyy"
        ... )
        >>> print(result['translation']['text'])
    """
    ocr = DeepseekOCR(api_key=deepseek_api_key)

    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
    processed_path = DeepseekOCR.preprocess_image(image_path)

    # OCR + Translation
    result = await ocr.recognize_with_translation(
        processed_path,
        target_lang=target_lang,
        translator_api_key=openai_api_key
    )

    return result


def estimate_ocr_cost(
    num_images: int,
    avg_size_mb: float = 2.0
) -> float:
    """
    ∆Ø·ªõc t√≠nh chi ph√≠ OCR

    Deepseek OCR pricing (example):
    - $0.002 per image (< 5MB)
    - $0.005 per image (5-20MB)

    Args:
        num_images: S·ªë l∆∞·ª£ng ·∫£nh
        avg_size_mb: K√≠ch th∆∞·ªõc trung b√¨nh (MB)

    Returns:
        Chi ph√≠ ∆∞·ªõc t√≠nh (USD)
    """
    if avg_size_mb <= 5:
        cost_per_image = 0.002
    else:
        cost_per_image = 0.005

    return num_images * cost_per_image


# =============================================================================
# Demo & Testing
# =============================================================================

async def demo_ocr():
    """Demo OCR v·ªõi Deepseek"""
    import os

    api_key = os.getenv("DEEPSEEK_API_KEY", "sk-test")
    ocr = DeepseekOCR(api_key=api_key)

    print("üîç Deepseek OCR Demo")
    print("=" * 50)

    # Example: Nh·∫≠n d·∫°ng ·∫£nh
    try:
        result = await ocr.recognize_image(
            "sample_handwriting.jpg",
            language="vi",
            mode="handwriting"
        )

        print(f"\nüìÑ VƒÉn b·∫£n nh·∫≠n d·∫°ng:")
        print(result.text)
        print(f"\n‚úÖ ƒê·ªô tin c·∫≠y: {result.confidence:.2%}")
        print(f"üåê Ng√¥n ng·ªØ: {result.language}")
        print(f"‚è±Ô∏è  Th·ªùi gian: {result.processing_time:.2f}s")

    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")


if __name__ == "__main__":
    # Run demo
    asyncio.run(demo_ocr())
